{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92e4685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87617e",
   "metadata": {},
   "source": [
    "#### Load dataframe into spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd69c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pddf = pd.read_csv('people.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4ee7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6d18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark =SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b88e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5998c4-07f3-4b4b-b181-4c3de4f12788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a78c45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://kinxps:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2599f90e588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1539bf4-9ae5-4f89-a095-6e74479460ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5be863-7c5e-4ca2-881d-6dc4f21aa5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3dce6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('people.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "460c665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "| _c0|_c1|       _c2|\n",
      "+----+---+----------+\n",
      "|Name|Age|Experience|\n",
      "|Taka| 20|         7|\n",
      "|Yuzu| 23|         5|\n",
      "|Sawa| 19|         4|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e13cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('people.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf251ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|Name|Age|Experience|\n",
      "+----+---+----------+\n",
      "|Taka| 20|         7|\n",
      "|Yuzu| 23|         5|\n",
      "|Sawa| 19|         4|\n",
      "+----+---+----------+\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()\n",
    "print(type(df_pyspark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f8941eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Taka', Age='20', Experience='7'),\n",
       " Row(Name='Yuzu', Age='23', Experience='5'),\n",
       " Row(Name='Sawa', Age='19', Experience='4')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a483a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reading as string, need to give another option in reading \n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "293c0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|Name|Age|Experience|\n",
      "+----+---+----------+\n",
      "|Taka| 20|         7|\n",
      "|Yuzu| 23|         5|\n",
      "|Sawa| 19|         4|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('people.csv',\n",
    "                            header = True,\n",
    "                            inferSchema = True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3654c036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pyspark dataframe\n",
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da690b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same as pandas\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd34e944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Taka', Age=20, Experience=7),\n",
       " Row(Name='Yuzu', Age=23, Experience=5),\n",
       " Row(Name='Sawa', Age=19, Experience=4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "370e99a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yuzu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sawa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name\n",
       "0  Taka\n",
       "1  Yuzu\n",
       "2  Sawa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+----+\n",
      "|Name|\n",
      "+----+\n",
      "|Taka|\n",
      "|Yuzu|\n",
      "|Sawa|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select a column pd vs spark\n",
    "display(pddf[['Name']])\n",
    "print(type(df_pyspark.select('Name')))\n",
    "df_pyspark.select('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aa5fe71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taka</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yuzu</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sawa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name  Experience\n",
       "0  Taka           7\n",
       "1  Yuzu           5\n",
       "2  Sawa           4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|Name|Experience|\n",
      "+----+----------+\n",
      "|Taka|         7|\n",
      "|Yuzu|         5|\n",
      "|Sawa|         4|\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select mutiple columns\n",
    "display(pddf[['Name', 'Experience']])\n",
    "df_pyspark.select(['Name', 'Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "137af6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "380aeba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n",
      "None\n",
      "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]\n"
     ]
    }
   ],
   "source": [
    "print(df_pyspark.printSchema())\n",
    "print(df_pyspark.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a5306e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.666667</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.081666</td>\n",
       "      <td>1.527525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.500000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.500000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age  Experience\n",
       "count   3.000000    3.000000\n",
       "mean   20.666667    5.333333\n",
       "std     2.081666    1.527525\n",
       "min    19.000000    4.000000\n",
       "25%    19.500000    4.500000\n",
       "50%    20.000000    5.000000\n",
       "75%    21.500000    6.000000\n",
       "max    23.000000    7.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------------------+------------------+\n",
      "|summary|Name|               Age|        Experience|\n",
      "+-------+----+------------------+------------------+\n",
      "|  count|   3|                 3|                 3|\n",
      "|   mean|null|20.666666666666668| 5.333333333333333|\n",
      "| stddev|null|2.0816659994661326|1.5275252316519468|\n",
      "|    min|Sawa|                19|                 4|\n",
      "|    max|Yuzu|                23|                 7|\n",
      "+-------+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(pddf.describe())\n",
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96ef6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns in dataframe\n",
    "df_pyspark = df_pyspark.withColumn('Experience after 2 years', df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99a82c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------------------------+\n",
      "|Name|Age|Experience|Experience after 2 years|\n",
      "+----+---+----------+------------------------+\n",
      "|Taka| 20|         7|                       9|\n",
      "|Yuzu| 23|         5|                       7|\n",
      "|Sawa| 19|         4|                       6|\n",
      "+----+---+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b923dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns\n",
    "df_pyspark = df_pyspark.drop('Experience after 2 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86754c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|Name|Age|Experience|\n",
      "+----+---+----------+\n",
      "|Taka| 20|         7|\n",
      "|Yuzu| 23|         5|\n",
      "|Sawa| 19|         4|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c70e53ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+\n",
      "|Name|Age|Exp|\n",
      "+----+---+---+\n",
      "|Taka| 20|  7|\n",
      "|Yuzu| 23|  5|\n",
      "|Sawa| 19|  4|\n",
      "+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rename the columns\n",
    "df_pyspark = df_pyspark.withColumnRenamed('Experience', 'Exp').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcdd399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
